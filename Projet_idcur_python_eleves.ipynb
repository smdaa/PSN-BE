{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Simulation Numérique ENSEEIHT 2020-2021\n",
    "### Groupe: \n",
    "### Nom:\n",
    "### Prénom: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informations pratiques\n",
    "\n",
    "**Modalités pédagogiques** \n",
    "\n",
    "Le projet Simulation Numérique vise à vous faire découvrir un algorithme particulier en lien avec d'autres modules d'enseignement de cette année et d'illustrer certaines notions et propriétés à partir de programmes simples que vous devez écrire ou bien compléter. Le langage de programmation proposé est Python. Une connaissance basique de Python et de Numpy est suffisante. \n",
    "\n",
    "Cette année, il vous est demandé en premier lieu un travail de compréhension des algorithmes principaux sur la base du C/TD du 6/4/21 et des liens en fin de Notebook. Ensuite est demandé un travail d'implantation informatique simple (partie A) et quelques applications sur des données synthétiques ou pratiques vous sont proposées (partie B). Ce travail est notamment guidé, des questions de compréhension sont enfin posées en Partie C. Le volume de travail demandé est raisonnable.\n",
    "\n",
    "**Enseignement à distance**\n",
    "\n",
    "Voici les informations concernant les séances à distance (date, heure, lien, numéro de réunion, mot de passe):\n",
    "\n",
    "06/4/21 08.00-09.45 https://zoom.us/j/3060702500?pwd=T2Fya0JCRHExeHpFRTVDNC9CanUwUT09  306 070 2500 86KhS8\n",
    "\n",
    "16/4/21 08.00-11.45 https://zoom.us/j/3060702500?pwd=T2Fya0JCRHExeHpFRTVDNC9CanUwUT09  306 070 2500 86KhS8\n",
    "\n",
    "04/5/21 10.00-11.45 https://zoom.us/j/3060702500?pwd=T2Fya0JCRHExeHpFRTVDNC9CanUwUT09  306 070 2500 86KhS8\n",
    "\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "L'évaluation se basera uniquement sur le Notebook que vous devrez rendre. \n",
    "\n",
    "**Date limite de rendu**:  12 mai 2021\n",
    "\n",
    "**Contact**: xavier.vasseur@isae-supaero.fr\n",
    "\n",
    "Merci d'indiquer [N7-PSN] en sujet de votre email pour m'aider à identifier vos requêtes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Préambule** L'objectif de ce projet est d'analyser quelques algorithmes de factorisation structurée (déterministe ou aléatoire) de matrices de grande taille. Nous nous intéressons à des algorithmes de factorisation dits \"Interpolative Decomposition (ID)\" ou \"CUR-ID\", où l'on cherche à approcher au mieux une matrice en un produit de matrices de rang faible. Les algorithmes seront comparés si possible sous différents angles: temps de calcul, complexité opératoire, précision numérique notamment. \n",
    "\n",
    "**NB:** Il vous est demandé d'insérer vos commentaires et codes **uniquement** dans ce fichier Notebook. Vous avez toute liberté pour créer des cellules soit de texte soit de code. Vous devez disposer comme données de ce fichier et de quelques images au format .jpg. Le rendu sera uniquement ce fichier Notebook dans lequel vous devez insérer l'ensemble de vos résultats. \n",
    "\n",
    "Ce projet est en lien notamment avec les cours suivants:\n",
    "\n",
    "   * Calcul scientifique\n",
    "   * Analyse de données\n",
    "   * Optimisation II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Chargement des bibliotheques pour la visualisation, l'algebre lineaire et l'analyse du temps de calcul \n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from   scipy import fftpack\n",
    "from   scipy.linalg import qr, norm, solve_triangular, svd\n",
    "from   PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction.\n",
    "\n",
    "L'approximation de rang faible que nous utiliserons dans ce projet se base sur une connaissance du rang exact ou du rang approché de la matrice étudiée. A titre informatif, la méthode suivante vous permet d'obtenir une majoration du rang d'une matrice rectangulaire $A$ telle que $ \\|A - Q Q^T A \\|_F \\le \\epsilon \\|A \\|_F$, $\\epsilon$ désignant une tolérance choisie par l'utilisateur. Cette méthode sera donc utile par la suite dans vos expérimentations numériques, aucune modification n'est a priori requise.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_rank_determination(A,epsilon,blocking=16):\n",
    "    \"\"\"\n",
    "    Adaptive rank determination based on randomization\n",
    "    We look for an orthogonal matrix Q such that \n",
    "    $\\|A - Q Q^T A \\|_F \\le \\epsilon \\|A \\|_F$\n",
    "    where $\\|.\\|_F$ denotes the Frobenius norm.\n",
    "    \n",
    "    Reference: Adapted from Section 12 of P.G. Martinsson, \"Randomized methods for matrix computations\", 2019, \n",
    "    ArXiv 1607.01649 [https://arxiv.org/pdf/1607.01649.pdf]. The original algorithm corresponds to \n",
    "    Figure 12. \n",
    "    \n",
    "    Input: \n",
    "    A:        matrix to be analysed [array type] (of shape (m,n))\n",
    "    epsilon:  relative threshold related to the accuracy of the projection (in the Frobenius norm) (0<= epsilon <= 1)\n",
    "    blocking: blocking parameter to be used in the implementation (for efficiency reasons) [int]\n",
    "    \n",
    "    Output:\n",
    "    Q: matrix with orthonormal columns such that $ \\|A - Q Q^T A \\|_F \\le \\epsilon \\|A \\|_F$\n",
    "    erank: estimated rank (upper bound of rank(A)), erank is here a multiple of min(blocking,n). \n",
    "    \"\"\" \n",
    "    \n",
    "    m, n       = A.shape[:]\n",
    "    b          = min(blocking,n)\n",
    "    iteration  = 0\n",
    "    norm_A_Fro = norm(A)\n",
    "    \n",
    "    while norm(A) > epsilon*norm_A_Fro:\n",
    "        # Create R the random block based on Gaussian variables\n",
    "        R      = np.random.randn(n,b)\n",
    "        # Matrix-matrix product Y = AR \n",
    "        Y      = A@R\n",
    "        # QR decomposition of Y\n",
    "        QY, RY = qr(Y,mode='economic')\n",
    "        # Compute the projection \n",
    "        BY     = QY.T@A\n",
    "        # Concatenate the information related to Q and B\n",
    "        if iteration == 0:\n",
    "            Q  = QY\n",
    "            B  = BY\n",
    "        else:\n",
    "            Q  = np.concatenate((Q, QY),axis=1)\n",
    "            B  = np.concatenate((B, BY),axis=0)\n",
    "        # Update the iteration count\n",
    "        iteration += 1\n",
    "        # Update of A\n",
    "        A = A - QY@BY\n",
    "        # Upper bound of rank\n",
    "        erank = Q.shape[1]\n",
    "        \n",
    "    return Q, erank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie A.1\n",
    "\n",
    "Proposer une implantation des différents algorithmes de décomposition vus en cours. Pour vous aider, une définition des fonctions et leurs squelettes sont proposés. Vous avez toute liberté pour les modifier. Ces algorithmes seront utilisés dans la partie de validation (Partie B) et applicative du Notebook (Partie C). Vous pourrez vous appuyer sur les <a href=\"https://arxiv.org/pdf/1607.01649.pdf\">chapitres 10 et 11 des notes de cours de P.G. Martinsson</a>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_ID(A,k):\n",
    "    \"\"\"\n",
    "    Compute a column interpolative decomposition such that \n",
    "    A \\approx A[:,J] Z\n",
    "    \n",
    "    Input: \n",
    "    A matrix to be analysed [array] (of shape (m,n))\n",
    "    k: estimated rank of matrix A [int]\n",
    "    \n",
    "    Output:\n",
    "    J  is the set of column indices [array, any type] (of shape k)\n",
    "    Z  is the corresponding matrix (of shape (k,n))\n",
    "    \n",
    "    Reference: Section 10.3 and Figure 7 of Martinsson's tutorial [https://arxiv.org/pdf/1607.01649.pdf].\n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = A.shape[:]\n",
    "    Z    = np.zeros(shape=(k,n))\n",
    "    \n",
    "    # Perform the economic decomposition of A with column pivoting \n",
    "    \n",
    "    \n",
    "    # Deduce the T=R11^{-1}R12 block \n",
    "    \n",
    "    \n",
    "    # Deduce J and Z \n",
    "    \n",
    "        \n",
    "    return J,Z\n",
    "\n",
    "\n",
    "def row_ID(A,k):\n",
    "    \"\"\"\n",
    "    Compute a row interpolative decomposition such that \n",
    "    A \\approx X A[I,:] \n",
    "    \n",
    "    Input: \n",
    "    A matrix to be analysed [any type] (of shape (m,n))\n",
    "    k: estimated rank of matrix A [int]\n",
    "    \n",
    "    Output:\n",
    "    I  is the set of row indices [array, any type] (of shape k)\n",
    "    X  is the corresponding matrix (of shape (m,k))\n",
    "    \n",
    "    Reference: Section 10.3 and Figure 7 of Martinsson's tutorial [https://arxiv.org/pdf/1607.01649.pdf].\n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = A.shape[:]\n",
    "    X    = np.zeros(shape=(m,k))\n",
    "    \n",
    "    # Perform the economic decomposition of A^T with column pivoting \n",
    "    \n",
    "        \n",
    "    # Deduce the corresponding T block \n",
    "    \n",
    "    \n",
    "    # Deduce I and X \n",
    "    \n",
    "    \n",
    "    return I,X\n",
    "\n",
    "def double_sided_ID(A,k):\n",
    "    \"\"\"\n",
    "    Compute a double sided interpolative decomposition such that \n",
    "    A \\approx X A(I,J) Z \n",
    "    \n",
    "    Input: \n",
    "    A matrix to be analysed [array type] (of shape (m,n))\n",
    "    k: estimated rank of matrix A [int]\n",
    "    \n",
    "    Output:\n",
    "    I  is the set of row indices [array] (of shape k)\n",
    "    J  is the set of column indices [array] (of shape k)\n",
    "    X  is the corresponding matrix (of shape (m,k))\n",
    "    Z  is the corresponding matrix (of shape (k,n))\n",
    "    \n",
    "    Reference: Section 10.3 and Figure 7 of Martinsson's tutorial [https://arxiv.org/pdf/1607.01649.pdf].\n",
    "    \"\"\"\n",
    "    # Apply the column ID to A\n",
    "    \n",
    "   \n",
    "    # Apply the row ID to A[:,J]\n",
    "    \n",
    "    \n",
    "    return I,J,X,Z\n",
    "\n",
    "def extract_subblock(A,I,J):\n",
    "    \"\"\"\n",
    "    Given a set of row and column indices, extract the submatrix \n",
    "    B = A[I,J]\n",
    "    with I the set of row indices and J the set of column indices.\n",
    "    \n",
    "    Input: \n",
    "    A matrix to be analysed [array] (of shape (m,n))\n",
    "    I  is the set of row indices  (of shape k)\n",
    "    J  is the set of column indices  (of shape k)\n",
    "    \n",
    "    Output:\n",
    "    Matrix A[I,J] [array] (of shape (k,k))\n",
    "    \"\"\"\n",
    "    B = np.zeros(shape=(len(I),len(J)))\n",
    "    row_index = 0\n",
    "    \n",
    "    for i in I:\n",
    "        col_index = 0\n",
    "        for j in J:\n",
    "            B[row_index,col_index] = A[i,j]\n",
    "            col_index = col_index + 1\n",
    "            \n",
    "        row_index = row_index + 1\n",
    "    \n",
    "    return B\n",
    "\n",
    "def cur(A,k):\n",
    "    \"\"\"\n",
    "    Deterministic version of the CUR algorithm based on the \n",
    "    double sided ID decomposition. \n",
    "    \n",
    "    Input: \n",
    "    A matrix to be analysed [any type] (of shape (m,n))\n",
    "    k: estimated rank of matrix A [int]  \n",
    "    \n",
    "    Output:\n",
    "    C  is the corresponding matrix (of shape (m,k))\n",
    "    U  is the corresponding matrix (of shape (k,k))\n",
    "    R  is the corresponding matrix (of shape (k,n))\n",
    "    \n",
    "    Reference: Section 11.2 of Martinsson's tutorial.\n",
    "    \"\"\"\n",
    "    # Apply the double sided interpolation algorithm \n",
    "    \n",
    "    \n",
    "    # Deduce the C and R matrices of the CUR formulation \n",
    "    \n",
    "    \n",
    "    # Deduce U\n",
    "    \n",
    "     \n",
    "    return I,J,C,U,R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie A.2 \n",
    "\n",
    "Proposer une implantation des différents algorithmes aléatoires de décomposition vus en cours. Pour vous aider, une définition des fonctions et leurs squelettes sont proposés. Vous avez toute liberté pour les modifier. Ces algorithmes seront utilisés dans la partie de validation (Partie B) et applicative du Notebook (Partie C). Vous pourrez vous appuyer sur les <a href=\"https://arxiv.org/pdf/1607.01649.pdf\">chapitres 10 et 11 des notes de cours de P.G. Martinsson</a>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_row_ID(A,k,p=10,q=2):\n",
    "    \"\"\"\n",
    "    Randomized version of the row ID to decompose matrix A into\n",
    "    A \\approx X A(I,:) \n",
    "    \n",
    "    Input: \n",
    "    A matrix to be analysed [array] (of shape (m,n))\n",
    "    k: estimated rank of matrix A [int]\n",
    "    p: oversampling parameter (p=10 by default)\n",
    "    q: number of power iterations (q=2 by default)\n",
    "    \n",
    "    Output:\n",
    "    I  is the set of row indices  (of shape k)\n",
    "    X  is the corresponding matrix (of shape (m,k))\n",
    "    \n",
    "    Reference: Section 10.4 and Figure 8 of Martinsson's tutorial [https://arxiv.org/pdf/1607.01649.pdf].\n",
    "    \n",
    "    \"\"\"\n",
    "    m, n = A.shape[:]\n",
    "    X    = np.zeros(shape=(m,k)) \n",
    "    \n",
    "    # Use the randomized variant to construct Y an approximation of A\n",
    "    G    = np.random.randn(n,k+p)\n",
    "    \n",
    "     \n",
    "    # Apply the row ID algorithm to Y\n",
    "    \n",
    "    return I,X\n",
    "\n",
    "   \n",
    "def randomized_cur(A,k,p=10,q=2):\n",
    "    \"\"\"\n",
    "    Randomized version of the CUR algorithm     \n",
    "    \n",
    "    Input: \n",
    "    A matrix to be analysed [any type] (of shape (m,n))\n",
    "    k: estimated rank of matrix A [int]\n",
    "    p: oversampling parameter (p=10 by default)\n",
    "    q: number of power iterations (q=2 by default)  \n",
    "    \n",
    "    Output:\n",
    "    C  is the corresponding matrix (of shape (m,k))\n",
    "    U  is the corresponding matrix (of shape (k,k))\n",
    "    R  is the corresponding matrix (of shape (k,n))\n",
    "    \n",
    "    Reference: Section 11.2 and Figure 10 of Martinsson's tutorial [https://arxiv.org/pdf/1607.01649.pdf]\n",
    "    \"\"\"    \n",
    "    m, n = A.shape[:]\n",
    "    \n",
    "    # Randomized version starts here\n",
    "    # Use the randomized variant to construct Y an approximation of A\n",
    "     \n",
    "    G    = np.random.randn(k+p,m)\n",
    "        \n",
    "    # Apply the column ID algorithm to Y \n",
    "    \n",
    "    \n",
    "    # Apply the row ID algorithm to A[:,J]\n",
    "    \n",
    "        \n",
    "    # Deduce the CUR matrices (C, R and then U)\n",
    "        \n",
    "    return I,J,C,U,R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie B.1\n",
    "\n",
    "Le but de cette partie est de valider vos implantations algorithmiques réalisées en Partie A. Construire explicitement une famille de matrices de taille $m \\times n$ de rang $k$ avec $k \\le min(m,n)$ qui vous semble pertinente et analyser la qualité de la solution obtenue pour les différentes méthodes. Dans une seconde étape, il vous est demandé de commenter vos résultats directement au sein du Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Simple example\n",
    "#\n",
    "def matrix(m,n):\n",
    "    \"\"\"\n",
    "    Define here the matrix to be used for validating the various algorithms defined in Part A.  \n",
    "    m : number of rows of A\n",
    "    n : number of columns of A\n",
    "    \n",
    "    A: matrix of shape (m,n)\n",
    "    \"\"\"\n",
    "\n",
    "    # This is just an illustration\n",
    "    # Please insert here your own example(s)\n",
    "    A = numpy.random.randn(m,n)\n",
    "    \n",
    "    return A\n",
    "\n",
    "#\n",
    "# Test the deterministic and randomized variants of CUR \n",
    "#\n",
    "\n",
    "m, n = 100, 20\n",
    "k    = n\n",
    "\n",
    "A = matrix(m,n)\n",
    "\n",
    "# double_sided_ID\n",
    "I, J, X, Z    = double_sided_ID(A,k)\n",
    "print(np.linalg.norm(A-X@extract_subblock(A,I,J)@Z)/np.linalg.norm(A))\n",
    "\n",
    "# CUR-ID\n",
    "I, J, C, U, R = cur(A,k)\n",
    "print(np.linalg.norm(A-C@U@R)/np.linalg.norm(A))\n",
    "\n",
    "# Randomized CUR\n",
    "I, J, C, U, R = randomized_cur(A,k)\n",
    "print(np.linalg.norm(A-C@U@R)/np.linalg.norm(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie B.2 \n",
    "\n",
    "Nous cherchons à mettre en oeuvre les algorithmes précédents sur une application liée à la reconstruction d'images.\n",
    "La cellule suivante vous montre comment charger une image et en déduire la matrice associée. Appliquer alors les algorithmes de \n",
    "factorisation vus en Partie A et visualiser l'image obtenue en fonction du rang estimé. Observez-vous des différences de qualité de reconstruction entre les algorithmes pour une précision identique ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Lecture de l'image parmi dog.jpg et jupiter.jpg [couleur] \n",
    "#\n",
    "#\n",
    "imgc = Image.open(\"dog.jpg\")\n",
    "\n",
    "#\n",
    "# Conversion de l'image RGB en mode gris et normalisation\n",
    "#\n",
    "img      = np.array(imgc)\n",
    "R        = img[:, :, 0]\n",
    "G        = img[:, :, 1]\n",
    "B        = img[:, :, 2]\n",
    "img_gray = R * 299. / 1000 + G * 587. / 1000 + B * 114. / 1000\n",
    "    \n",
    "M        = (1./255)*np.array(img_gray)\n",
    "#\n",
    "# Affichage de la taille de l'image et de l'image en gris si besoin\n",
    "#\n",
    "print(np.shape(M))\n",
    "plt.imshow(M,'gray')\n",
    "#\n",
    "# Constantes utiles par la suite\n",
    "#\n",
    "m     = np.shape(M)[0] # nombre de lignes de la matrice M\n",
    "n     = np.shape(M)[1] # nombre de colonnes de la matrice M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Application of the ID/CUR algorithms to M with erank as target rank\n",
    "#\n",
    "epsilon  = 1.e-2\n",
    "blocking = 128\n",
    "t_start  = time.time()\n",
    "Q, erank = adaptive_rank_determination(M,epsilon,blocking)\n",
    "print(\"Time spent in the determination of the approximated rank\",time.time()-t_start) \n",
    "print(\"Estimated rank: \",erank, \" for relative threshold: \",epsilon)\n",
    "#\n",
    "# Randomized CUR algorithm\n",
    "#\n",
    "p = 5\n",
    "q = 1\n",
    "t_start        = time.time()\n",
    "I, J, C, U, R  = randomized_cur(M,erank,p,q)\n",
    "JCUR_R         = C@U@R\n",
    "print(\"Time spent in the randomized CUR algorithm\",time.time()-t_start) \n",
    "#\n",
    "# Double sided ID\n",
    "#\n",
    "t_start        = time.time()\n",
    "I,J,X,Z        = double_sided_ID(M,erank)\n",
    "JID            = X @ extract_subblock(M,I,J) @ Z\n",
    "print(\"Time spent in the double sided ID algorithm\",time.time()-t_start)\n",
    "#\n",
    "# CUR algorithm\n",
    "#\n",
    "t_start        = time.time()\n",
    "I,J,C, U, R    = cur(M,erank)\n",
    "JCUR_D         = C@U@R\n",
    "print(\"Time spent in the CUR algorithm\",time.time()-t_start)\n",
    "#\n",
    "# Plots\n",
    "#\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(M,'gray')\n",
    "plt.title('True image',fontsize=24)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(JCUR_D,'gray')\n",
    "plt.title('CUR',fontsize=24)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(JCUR_R,'gray')\n",
    "plt.title('Randomized CUR',fontsize=24)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(M,'gray')\n",
    "plt.title('True image',fontsize=24)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(JCUR_D,'gray')\n",
    "plt.title('CUR',fontsize=24)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(JID,'gray')\n",
    "plt.title('Double sided ID',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Lecture de l'image parmi dog.jpg et jupiter.jpg [couleur] \n",
    "#\n",
    "#\n",
    "imgc = Image.open(\"jupiter.jpg\")\n",
    "\n",
    "#\n",
    "# Conversion de l'image RGB en mode gris et normalisation\n",
    "#\n",
    "img      = np.array(imgc)\n",
    "R        = img[:, :, 0]\n",
    "G        = img[:, :, 1]\n",
    "B        = img[:, :, 2]\n",
    "img_gray = R * 299. / 1000 + G * 587. / 1000 + B * 114. / 1000\n",
    "    \n",
    "M         = (1./255)*np.array(img_gray)\n",
    "print(np.shape(M))\n",
    "plt.imshow(M,'gray')\n",
    "#\n",
    "# Constantes utiles par la suite\n",
    "#\n",
    "m     = np.shape(M)[0] # nombre de lignes de la matrice M\n",
    "n     = np.shape(M)[1] # nombre de colonnes de la matrice M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Application of the ID/CUR algorithms to M with erank as target rank\n",
    "#\n",
    "epsilon  = 1.e-3\n",
    "blocking = 128\n",
    "t_start  = time.time()\n",
    "Q, erank = adaptive_rank_determination(M,epsilon,blocking)\n",
    "print(\"Time spent in the determination of the approximated rank\",time.time()-t_start) \n",
    "print(\"Estimated rank: \",erank, \" for relative threshold: \",epsilon)\n",
    "#\n",
    "# Randomized CUR algorithm\n",
    "#\n",
    "p = 5\n",
    "q = 1\n",
    "t_start        = time.time()\n",
    "I,J,C, U, R    = randomized_cur(M,erank,p,q)\n",
    "JCUR_R         = C@U@R\n",
    "print(\"Time spent in the randomized CUR algorithm\",time.time()-t_start) \n",
    "#\n",
    "# Double sided ID\n",
    "#\n",
    "t_start  = time.time()\n",
    "I,J,X,Z  = double_sided_ID(M,erank)\n",
    "JID      = X @ extract_subblock(M,I,J) @ Z\n",
    "print(\"Time spent in the double sided ID algorithm\",time.time()-t_start)\n",
    "#\n",
    "# CUR algorithm\n",
    "#\n",
    "t_start        = time.time()\n",
    "I,J,C, U, R    = cur(M,erank)\n",
    "JCUR_D         = C@U@R\n",
    "print(\"Time spent in the CUR algorithm\",time.time()-t_start)\n",
    "#\n",
    "# Plots\n",
    "#\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(M,'gray')\n",
    "plt.title('True image',fontsize=24)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(JCUR_D,'gray')\n",
    "plt.title('Deterministic CUR',fontsize=24)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(JCUR_R,'gray')\n",
    "plt.title('Randomized CUR',fontsize=24)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(M,'gray')\n",
    "plt.title('True image',fontsize=24)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(JCUR_D,'gray')\n",
    "plt.title('Deterministic CUR',fontsize=24)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(JID,'gray')\n",
    "plt.title('Double sided ID',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie C.\n",
    "\n",
    "En vous basant notamment sur les notes de cours, les chapitres 10 et 11 de <a href=\"https://arxiv.org/pdf/1607.01649.pdf\">Martinsson (2019)</a>, la section 13 de <a href=\"https://arxiv.org/pdf/2002.01387.pdf\">Martinsson et Tropp (2020)</a>,  répondre aux questions suivantes:\n",
    "\n",
    "* C.1 Donner les avantages et inconvénients éventuels de la décomposition ID (version déterministe colonne, ligne ou double) ? \n",
    "\n",
    "**Réponse**:\n",
    "\n",
    "* C.2 Quelle est la complexité opératoire de la méthode colonne ID (version déterministe) ? Justifier ce résultat dans le cas d'une matrice dense $A \\in \\mathbb{R}^{m \\times n}$. Vous pourrez par exemple détailler la complexité étape par étape pour plus de clarté en vous basant sur une méthode QR avec pivotage de colonne pour obtenir cette décomposition. \n",
    "\n",
    "**Réponse**:\n",
    "\n",
    "* C.3 Quel théoreme permet d'affirmer que $\\sigma_{k+1}(A) \\le \\| E \\|_2$ avec $E$ la matrice d'erreur d'approximation lors de la construction d'une approximation de rang $k$ obtenue avec toute méthode basée sur la décomposition interpolative ID ? \n",
    "\n",
    "**Réponse**:\n",
    "\n",
    "* C.4 Quel est selon vous l'avantage principal des méthodes ID par rapport aux méthodes basées sur la décomposition CUR-ID ? Vous pourrez baser votre raisonnement et votre analyse sur l'expérimentation numérique proposée en Partie B.\n",
    "\n",
    "**Réponse**:\n",
    "\n",
    "\n",
    "\n",
    "* C.5 Expliquer les raisons qui ont conduit à proposer des variantes aléatoires de ces algorithmes ?\n",
    "\n",
    "**Réponse**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Références (articles et exposés)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles\n",
    "\n",
    "* P.-G.  Martinsson.  <a href=\"https://arxiv.org/pdf/1607.01649.pdf\">Randomized  methods  for  matrix  computations</a>.  In  M.W.  Mahoney,  J.C.  Duchi,  and  A.C.  Gilbert, editors, The Mathematics of Data, volume 25, chapter 4, pages 187 – 231. American Mathematical Society, IAS/ParkCity Mathematics Series, 2018.\n",
    "\n",
    "\n",
    "* P.-G.  Martinsson and J. Tropp.  <a href=\"https://arxiv.org/pdf/2002.01387.pdf\">Randomized Numerical Linear Algebra: Foundations & Algorithms</a>. Acta Numerica, 29, pp 403-572, 2020.\n",
    "\n",
    "\n",
    "* S. Voronin, P.-G.  Martinsson and  <a href=\"https://users.oden.utexas.edu/~pgm/Pubs/2017_voronin_CUR.pdf\">Efficient Algorithms for CUR and Interpolative Matrix Decompositions</a>. Advances in Computational Mathematics, Volume 43, Issue 3, pp 495–516, 2017.\n",
    "\n",
    "### Exposés\n",
    "\n",
    "* P.-G.  Martinsson. <a href=\"https://simons.berkeley.edu/talks/randomized-algorithms-computing-full-matrix-factorizations\">Randomized Algorithms for Computing Full Matrix Factorizations</a>, talk given at  \n",
    "Randomized Numerical Linear Algebra and Applications, September 2018, Simons Institute, Berkeley, 2018.\n",
    "\n",
    "\n",
    "* P.-G.  Martinsson. <a href=\"https://www.youtube.com/watch?v=l262Qij6flM\">Randomized algorithms for pivoting and for computing interpolatory and CUR factorizations</a>, talk given at E-Numerical Linear Algebra seminars, March 2021.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
